{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.181285Z",
     "start_time": "2020-01-15T03:31:28.036885Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "from torch.utils.data import  DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.186804Z",
     "start_time": "2020-01-15T03:31:29.183467Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_parameters_init(model):\n",
    "    '''\n",
    "    kaiming init\n",
    "    '''\n",
    "    for p in model.parameters():\n",
    "        if len(p.shape) >= 2:\n",
    "            nn.init.kaiming_normal_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T04:40:51.104875Z",
     "start_time": "2020-01-15T04:40:51.098612Z"
    }
   },
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    '''\n",
    "    只输入一个aqi，其他置0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(NetWork,self).__init__()\n",
    "        self.lstm = nn.LSTM(24, 50, 1, batch_first= True)\n",
    "        self.linear_1 = nn.Linear(50, 10)\n",
    "        self.linear_2 = nn.Linear(10, 1)\n",
    "        self.relu = nn.PReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x,(h_1,c_1) = self.lstm(x)\n",
    "        x = x[:,24:,:]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.233203Z",
     "start_time": "2020-01-15T03:31:29.230305Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''\n",
    "    transform sample to tensor\n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        sample['x'] = torch.from_numpy(sample['x']).float()\n",
    "        sample['y'] = torch.from_numpy(sample['y']).float()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.240260Z",
     "start_time": "2020-01-15T03:31:29.234560Z"
    }
   },
   "outputs": [],
   "source": [
    "class AqiDataset():\n",
    "    '''\n",
    "    用于获取aqi训练与测试数据\n",
    "    '''\n",
    "    def __init__(self, data, transforms= None):\n",
    "        '''\n",
    "        data: samples of ndarray from csv\n",
    "        '''\n",
    "        self.data = data.copy()\n",
    "        #前24气象要素用不到，只取aqi\n",
    "        #后面71个取不到\n",
    "        self.size = len(data) - 71 - 24\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self):\n",
    "        print('使用__getitem__(idx)获取数据')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        定义了__getitem__魔法函数，该类就可以下标操作了：[]\n",
    "        '''\n",
    "        #历史24时刻数据\n",
    "        history = self.data[idx : idx + 24].copy()\n",
    "        #未来72时刻数据（不包括AQI）\n",
    "        future = self.data[idx + 24 : idx + 24 + 72].copy()\n",
    "        future[:,0] = 0\n",
    "        #合并\n",
    "        h_f = np.r_[history, future]\n",
    "        #取各个时刻的实测值\n",
    "        lables = self.data[idx + 24 : idx + 24 + 72, 0].copy()\n",
    "        #进行必要的变换\n",
    "        sample = {'x':h_f, 'y':lables}\n",
    "        sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.252143Z",
     "start_time": "2020-01-15T03:31:29.241524Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device):\n",
    "    #save model or not\n",
    "    if args.save_model:\n",
    "        if not os.path.exists(args.save_directory):\n",
    "            os.makedirs(args.save_directory)\n",
    "    \n",
    "    epochs = args.epochs\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch_id in range(epochs):\n",
    "        #monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        ######################\n",
    "        #training the model#\n",
    "        ######################\n",
    "        train_batch_cnt = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            train_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "            \n",
    "            # groundtruth\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #get out_puts\n",
    "            pred_y = model(x)\n",
    "            \n",
    "            #get loss\n",
    "            loss = criterion(y, pred_y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            #do bp\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #show log info\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]  MSELoss: {:.6f}'.format(\n",
    "                        epoch_id,\n",
    "                        batch_idx * len(x),\n",
    "                        len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()\n",
    "                        )\n",
    "                      )\n",
    "        #记录train_loss\n",
    "        train_loss /= train_batch_cnt\n",
    "        train_losses.append(train_loss)\n",
    "            \n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        valid_loss = 0.0\n",
    "        #change model mode to eval ,not use BN/Dropout\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_batch_cnt = 0\n",
    "\n",
    "            for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "                valid_batch_cnt += 1\n",
    "                x = batch['x']\n",
    "                y = batch['y']\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                pred_y = model(x)\n",
    "                \n",
    "                valid_loss_batch = criterion(y, pred_y)\n",
    "                valid_loss += valid_loss_batch.item()\n",
    "\n",
    "            valid_loss /= valid_batch_cnt * 1.0\n",
    "            #记录valid_loss\n",
    "            valid_losses.append(valid_loss)\n",
    "            print('Valid: MSELoss: {:.6f}'.format(valid_loss))\n",
    "        #学习率衰减\n",
    "        scheduler.step()\n",
    "        print('===========================================================')\n",
    "        #save model\n",
    "        if args.save_model and epoch_id % 10 == 0:\n",
    "            saved_model_name = os.path.join(args.save_directory, 'epoch' + '_' + str(epoch_id) + '.pt')\n",
    "            torch.save(model.state_dict(), saved_model_name)\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.259103Z",
     "start_time": "2020-01-15T03:31:29.254078Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(args, valid_loader, model, criterion, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_batch_cnt = 0\n",
    "        valid_loss = 0\n",
    "        for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "            valid_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_y = model(x)\n",
    "\n",
    "            valid_loss_batch = criterion(y, pred_y)\n",
    "            valid_loss += valid_loss_batch.item()\n",
    "\n",
    "        valid_loss /= valid_batch_cnt * 1.0\n",
    "        print('Valid: MSELoss: {:.6f}'.format(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.266395Z",
     "start_time": "2020-01-15T03:31:29.260515Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(args, predict_loader, model, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(predict_loader):\n",
    "            if i == args.idx:\n",
    "                x = data['x'].to(device)\n",
    "                y = data['y'].numpy()\n",
    "                pred_y = model(x)\n",
    "                pred_y = pred_y.cpu().numpy()\n",
    "                plt.figure(0,(8,6))\n",
    "                plt.plot(range(len(y[0])),y[0],'b-o')\n",
    "                plt.plot(range(len(y[0])),pred_y[0],'r-o')\n",
    "                plt.xlabel('Following 72 Hours')\n",
    "                plt.ylabel('AQI')\n",
    "                plt.legend(['obs','predict'])\n",
    "                plt.show()\n",
    "            elif i > args.idx:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:31:29.279673Z",
     "start_time": "2020-01-15T03:31:29.267802Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #设置随机种子\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #设置CPU/GPU\n",
    "    use_cuda = args.cuda and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    ###############################################################################################################\n",
    "    print('===> Loading Datasets')\n",
    "    #读数据\n",
    "    df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "    data = df.values\n",
    "    data[:,4] /= 10000\n",
    "    #划分样本集\n",
    "    trsf = transforms.Compose([ToTensor()])\n",
    "    train_set = AqiDataset(data[:18000], trsf)\n",
    "    test_set = AqiDataset(data[18000:27000], trsf)\n",
    "    val_set = AqiDataset(data[27000:], trsf)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=False, num_workers= 1, pin_memory= True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size, num_workers= 1, pin_memory= True)\n",
    "    predict_loader = torch.utils.data.DataLoader(val_set, batch_size=args.predict_batch_size, num_workers= 1, pin_memory= False)\n",
    "    ###############################################################################################################\n",
    "    print('===> Building Model')\n",
    "    print('===> runing on {}'.format(device))\n",
    "    ###############################################################################################################\n",
    "    print('===> init model')\n",
    "    model = NetWork()\n",
    "    ###############################################################################################################\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr= args.lr)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum= args.momentum)\n",
    "    #学习率衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1 , 0.95)\n",
    "    ###############################################################################################################\n",
    "    if args.phase == 'Train' or args.phase == 'train':\n",
    "        print('===> Start Training')\n",
    "        train_losses, valid_losses = train(args, train_loader, test_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Test' or args.phase == 'test':\n",
    "        print('===> Test')\n",
    "        test(args, test_loader, model, criterion, device)\n",
    "        print('===> Done!')\n",
    "        return None, None\n",
    "    elif args.phase == 'Finetune' or args.phase == 'finetune':\n",
    "        print('===> Finetune')\n",
    "        path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        train_losses, valid_losses = train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Predict' or args.phase == 'predict':\n",
    "        print('===> Predict')\n",
    "        predict(args, predict_loader, model, device)\n",
    "        print('===> Done!')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-15T05:32:33.503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading Datasets\n",
      "===> Building Model\n",
      "===> runing on cuda\n",
      "===> init model\n",
      "===> Start Training\n",
      "Train Epoch: 0 [0/17905 (0%)]  MSELoss: 13349.882812\n",
      "Train Epoch: 0 [3200/17905 (18%)]  MSELoss: 31522.896484\n",
      "Train Epoch: 0 [6400/17905 (36%)]  MSELoss: 2712.293945\n",
      "Train Epoch: 0 [9600/17905 (54%)]  MSELoss: 2895.623535\n",
      "Train Epoch: 0 [12800/17905 (71%)]  MSELoss: 12922.144531\n",
      "Train Epoch: 0 [16000/17905 (89%)]  MSELoss: 14143.368164\n",
      "Valid: MSELoss: 2328.827148\n",
      "===========================================================\n",
      "Train Epoch: 1 [0/17905 (0%)]  MSELoss: 1916.501343\n",
      "Train Epoch: 1 [3200/17905 (18%)]  MSELoss: 9797.538086\n",
      "Train Epoch: 1 [6400/17905 (36%)]  MSELoss: 4050.840332\n",
      "Train Epoch: 1 [9600/17905 (54%)]  MSELoss: 214.214066\n",
      "Train Epoch: 1 [12800/17905 (71%)]  MSELoss: 6305.147949\n",
      "Train Epoch: 1 [16000/17905 (89%)]  MSELoss: 10202.306641\n",
      "Valid: MSELoss: 2364.904150\n",
      "===========================================================\n",
      "Train Epoch: 2 [0/17905 (0%)]  MSELoss: 1636.000000\n",
      "Train Epoch: 2 [3200/17905 (18%)]  MSELoss: 9359.171875\n",
      "Train Epoch: 2 [6400/17905 (36%)]  MSELoss: 4770.921875\n",
      "Train Epoch: 2 [9600/17905 (54%)]  MSELoss: 435.325317\n",
      "Train Epoch: 2 [12800/17905 (71%)]  MSELoss: 6527.462402\n",
      "Train Epoch: 2 [16000/17905 (89%)]  MSELoss: 10874.497070\n",
      "Valid: MSELoss: 2407.199304\n",
      "===========================================================\n",
      "Train Epoch: 3 [0/17905 (0%)]  MSELoss: 1690.027588\n",
      "Train Epoch: 3 [3200/17905 (18%)]  MSELoss: 10315.684570\n",
      "Train Epoch: 3 [6400/17905 (36%)]  MSELoss: 5875.250000\n",
      "Train Epoch: 3 [9600/17905 (54%)]  MSELoss: 264.526306\n",
      "Train Epoch: 3 [12800/17905 (71%)]  MSELoss: 6854.595215\n",
      "Train Epoch: 3 [16000/17905 (89%)]  MSELoss: 11487.238281\n",
      "Valid: MSELoss: 2378.600134\n",
      "===========================================================\n",
      "Train Epoch: 4 [0/17905 (0%)]  MSELoss: 1559.617676\n",
      "Train Epoch: 4 [3200/17905 (18%)]  MSELoss: 9175.899414\n",
      "Train Epoch: 4 [6400/17905 (36%)]  MSELoss: 7284.367188\n",
      "Train Epoch: 4 [9600/17905 (54%)]  MSELoss: 547.246277\n",
      "Train Epoch: 4 [12800/17905 (71%)]  MSELoss: 7934.364746\n",
      "Train Epoch: 4 [16000/17905 (89%)]  MSELoss: 11203.298828\n",
      "Valid: MSELoss: 2464.929016\n",
      "===========================================================\n",
      "Train Epoch: 5 [0/17905 (0%)]  MSELoss: 1814.688354\n",
      "Train Epoch: 5 [3200/17905 (18%)]  MSELoss: 8949.613281\n",
      "Train Epoch: 5 [6400/17905 (36%)]  MSELoss: 6407.291504\n",
      "Train Epoch: 5 [9600/17905 (54%)]  MSELoss: 637.701721\n",
      "Train Epoch: 5 [12800/17905 (71%)]  MSELoss: 8747.587891\n",
      "Train Epoch: 5 [16000/17905 (89%)]  MSELoss: 11007.667969\n",
      "Valid: MSELoss: 2175.749573\n",
      "===========================================================\n",
      "Train Epoch: 6 [0/17905 (0%)]  MSELoss: 1667.266113\n",
      "Train Epoch: 6 [3200/17905 (18%)]  MSELoss: 9485.754883\n",
      "Train Epoch: 6 [6400/17905 (36%)]  MSELoss: 7935.715332\n",
      "Train Epoch: 6 [9600/17905 (54%)]  MSELoss: 1072.738770\n",
      "Train Epoch: 6 [12800/17905 (71%)]  MSELoss: 8119.993164\n",
      "Train Epoch: 6 [16000/17905 (89%)]  MSELoss: 10581.451172\n",
      "Valid: MSELoss: 2185.755103\n",
      "===========================================================\n",
      "Train Epoch: 7 [0/17905 (0%)]  MSELoss: 1824.161499\n",
      "Train Epoch: 7 [3200/17905 (18%)]  MSELoss: 9407.716797\n",
      "Train Epoch: 7 [6400/17905 (36%)]  MSELoss: 7955.612793\n",
      "Train Epoch: 7 [9600/17905 (54%)]  MSELoss: 851.707947\n",
      "Train Epoch: 7 [12800/17905 (71%)]  MSELoss: 8558.723633\n",
      "Train Epoch: 7 [16000/17905 (89%)]  MSELoss: 10582.593750\n",
      "Valid: MSELoss: 2185.494104\n",
      "===========================================================\n",
      "Train Epoch: 8 [0/17905 (0%)]  MSELoss: 1512.282104\n",
      "Train Epoch: 8 [3200/17905 (18%)]  MSELoss: 9994.556641\n",
      "Train Epoch: 8 [6400/17905 (36%)]  MSELoss: 9574.438477\n",
      "Train Epoch: 8 [9600/17905 (54%)]  MSELoss: 873.505676\n",
      "Train Epoch: 8 [12800/17905 (71%)]  MSELoss: 8057.250977\n",
      "Train Epoch: 8 [16000/17905 (89%)]  MSELoss: 10851.805664\n",
      "Valid: MSELoss: 2177.106519\n",
      "===========================================================\n",
      "Train Epoch: 9 [0/17905 (0%)]  MSELoss: 1386.462280\n",
      "Train Epoch: 9 [3200/17905 (18%)]  MSELoss: 9960.676758\n",
      "Train Epoch: 9 [6400/17905 (36%)]  MSELoss: 6920.361816\n",
      "Train Epoch: 9 [9600/17905 (54%)]  MSELoss: 958.083130\n",
      "Train Epoch: 9 [12800/17905 (71%)]  MSELoss: 9285.659180\n",
      "Train Epoch: 9 [16000/17905 (89%)]  MSELoss: 10526.739258\n",
      "Valid: MSELoss: 2181.505835\n",
      "===========================================================\n",
      "Train Epoch: 10 [0/17905 (0%)]  MSELoss: 1419.560303\n",
      "Train Epoch: 10 [3200/17905 (18%)]  MSELoss: 9873.120117\n",
      "Train Epoch: 10 [6400/17905 (36%)]  MSELoss: 7194.090820\n",
      "Train Epoch: 10 [9600/17905 (54%)]  MSELoss: 1324.190063\n",
      "Train Epoch: 10 [12800/17905 (71%)]  MSELoss: 8756.586914\n",
      "Train Epoch: 10 [16000/17905 (89%)]  MSELoss: 10230.647461\n",
      "Valid: MSELoss: 2239.324683\n",
      "===========================================================\n",
      "Train Epoch: 11 [0/17905 (0%)]  MSELoss: 1239.058350\n",
      "Train Epoch: 11 [3200/17905 (18%)]  MSELoss: 9767.218750\n",
      "Train Epoch: 11 [6400/17905 (36%)]  MSELoss: 8266.459961\n",
      "Train Epoch: 11 [9600/17905 (54%)]  MSELoss: 1614.698120\n",
      "Train Epoch: 11 [12800/17905 (71%)]  MSELoss: 9348.847656\n",
      "Train Epoch: 11 [16000/17905 (89%)]  MSELoss: 10623.607422\n",
      "Valid: MSELoss: 2240.834937\n",
      "===========================================================\n",
      "Train Epoch: 12 [0/17905 (0%)]  MSELoss: 1179.618286\n",
      "Train Epoch: 12 [3200/17905 (18%)]  MSELoss: 9700.796875\n",
      "Train Epoch: 12 [6400/17905 (36%)]  MSELoss: 5888.835449\n",
      "Train Epoch: 12 [9600/17905 (54%)]  MSELoss: 1041.120850\n",
      "Train Epoch: 12 [12800/17905 (71%)]  MSELoss: 8985.003906\n",
      "Train Epoch: 12 [16000/17905 (89%)]  MSELoss: 10222.754883\n",
      "Valid: MSELoss: 2259.184863\n",
      "===========================================================\n",
      "Train Epoch: 13 [0/17905 (0%)]  MSELoss: 1206.596313\n",
      "Train Epoch: 13 [3200/17905 (18%)]  MSELoss: 10041.560547\n",
      "Train Epoch: 13 [6400/17905 (36%)]  MSELoss: 7540.932129\n",
      "Train Epoch: 13 [9600/17905 (54%)]  MSELoss: 1079.275635\n",
      "Train Epoch: 13 [12800/17905 (71%)]  MSELoss: 9041.696289\n",
      "Train Epoch: 13 [16000/17905 (89%)]  MSELoss: 10295.709961\n",
      "Valid: MSELoss: 2246.245166\n",
      "===========================================================\n",
      "Train Epoch: 14 [0/17905 (0%)]  MSELoss: 1178.517090\n",
      "Train Epoch: 14 [3200/17905 (18%)]  MSELoss: 9844.421875\n",
      "Train Epoch: 14 [6400/17905 (36%)]  MSELoss: 7741.684082\n",
      "Train Epoch: 14 [9600/17905 (54%)]  MSELoss: 922.223633\n",
      "Train Epoch: 14 [12800/17905 (71%)]  MSELoss: 9154.677734\n",
      "Train Epoch: 14 [16000/17905 (89%)]  MSELoss: 10593.122070\n",
      "Valid: MSELoss: 2337.812305\n",
      "===========================================================\n",
      "Train Epoch: 15 [0/17905 (0%)]  MSELoss: 1085.396851\n",
      "Train Epoch: 15 [3200/17905 (18%)]  MSELoss: 9249.614258\n",
      "Train Epoch: 15 [6400/17905 (36%)]  MSELoss: 8772.128906\n",
      "Train Epoch: 15 [9600/17905 (54%)]  MSELoss: 903.331848\n",
      "Train Epoch: 15 [12800/17905 (71%)]  MSELoss: 10943.958008\n",
      "Train Epoch: 15 [16000/17905 (89%)]  MSELoss: 10303.188477\n",
      "Valid: MSELoss: 2344.552002\n",
      "===========================================================\n",
      "Train Epoch: 16 [0/17905 (0%)]  MSELoss: 1057.146729\n",
      "Train Epoch: 16 [3200/17905 (18%)]  MSELoss: 9409.316406\n",
      "Train Epoch: 16 [6400/17905 (36%)]  MSELoss: 9196.802734\n",
      "Train Epoch: 16 [9600/17905 (54%)]  MSELoss: 1181.590454\n",
      "Train Epoch: 16 [12800/17905 (71%)]  MSELoss: 9834.015625\n",
      "Train Epoch: 16 [16000/17905 (89%)]  MSELoss: 10063.883789\n",
      "Valid: MSELoss: 2363.817627\n",
      "===========================================================\n",
      "Train Epoch: 17 [0/17905 (0%)]  MSELoss: 1093.882202\n",
      "Train Epoch: 17 [3200/17905 (18%)]  MSELoss: 9211.861328\n",
      "Train Epoch: 17 [6400/17905 (36%)]  MSELoss: 8572.005859\n",
      "Train Epoch: 17 [9600/17905 (54%)]  MSELoss: 1285.433228\n",
      "Train Epoch: 17 [12800/17905 (71%)]  MSELoss: 10174.687500\n",
      "Train Epoch: 17 [16000/17905 (89%)]  MSELoss: 10143.462891\n",
      "Valid: MSELoss: 2355.279785\n",
      "===========================================================\n",
      "Train Epoch: 18 [0/17905 (0%)]  MSELoss: 1060.149292\n",
      "Train Epoch: 18 [3200/17905 (18%)]  MSELoss: 8914.128906\n",
      "Train Epoch: 18 [6400/17905 (36%)]  MSELoss: 8699.890625\n",
      "Train Epoch: 18 [9600/17905 (54%)]  MSELoss: 1074.398438\n",
      "Train Epoch: 18 [12800/17905 (71%)]  MSELoss: 10172.673828\n",
      "Train Epoch: 18 [16000/17905 (89%)]  MSELoss: 10336.458008\n",
      "Valid: MSELoss: 2339.746997\n",
      "===========================================================\n",
      "Train Epoch: 19 [0/17905 (0%)]  MSELoss: 1037.432251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [3200/17905 (18%)]  MSELoss: 9139.264648\n",
      "Train Epoch: 19 [6400/17905 (36%)]  MSELoss: 8437.041016\n",
      "Train Epoch: 19 [9600/17905 (54%)]  MSELoss: 1160.683105\n",
      "Train Epoch: 19 [12800/17905 (71%)]  MSELoss: 9860.441406\n",
      "Train Epoch: 19 [16000/17905 (89%)]  MSELoss: 10036.812500\n",
      "Valid: MSELoss: 2254.802637\n",
      "===========================================================\n",
      "Train Epoch: 20 [0/17905 (0%)]  MSELoss: 1459.779297\n",
      "Train Epoch: 20 [3200/17905 (18%)]  MSELoss: 9368.878906\n",
      "Train Epoch: 20 [6400/17905 (36%)]  MSELoss: 9077.410156\n",
      "Train Epoch: 20 [9600/17905 (54%)]  MSELoss: 632.476624\n",
      "Train Epoch: 20 [12800/17905 (71%)]  MSELoss: 9552.735352\n",
      "Train Epoch: 20 [16000/17905 (89%)]  MSELoss: 9816.841797\n",
      "Valid: MSELoss: 2340.981274\n",
      "===========================================================\n",
      "Train Epoch: 21 [0/17905 (0%)]  MSELoss: 1229.365112\n",
      "Train Epoch: 21 [3200/17905 (18%)]  MSELoss: 8925.035156\n",
      "Train Epoch: 21 [6400/17905 (36%)]  MSELoss: 7551.260254\n",
      "Train Epoch: 21 [9600/17905 (54%)]  MSELoss: 923.638000\n",
      "Train Epoch: 21 [12800/17905 (71%)]  MSELoss: 9473.182617\n",
      "Train Epoch: 21 [16000/17905 (89%)]  MSELoss: 10251.790039\n",
      "Valid: MSELoss: 2222.241602\n",
      "===========================================================\n",
      "Train Epoch: 22 [0/17905 (0%)]  MSELoss: 1124.331421\n",
      "Train Epoch: 22 [3200/17905 (18%)]  MSELoss: 9239.661133\n",
      "Train Epoch: 22 [6400/17905 (36%)]  MSELoss: 7545.522461\n",
      "Train Epoch: 22 [9600/17905 (54%)]  MSELoss: 787.794922\n",
      "Train Epoch: 22 [12800/17905 (71%)]  MSELoss: 9063.375977\n",
      "Train Epoch: 22 [16000/17905 (89%)]  MSELoss: 9919.252930\n",
      "Valid: MSELoss: 2320.497729\n",
      "===========================================================\n",
      "Train Epoch: 23 [0/17905 (0%)]  MSELoss: 1061.364624\n",
      "Train Epoch: 23 [3200/17905 (18%)]  MSELoss: 8869.684570\n",
      "Train Epoch: 23 [6400/17905 (36%)]  MSELoss: 7227.779785\n",
      "Train Epoch: 23 [9600/17905 (54%)]  MSELoss: 1273.467041\n",
      "Train Epoch: 23 [12800/17905 (71%)]  MSELoss: 9656.620117\n",
      "Train Epoch: 23 [16000/17905 (89%)]  MSELoss: 10136.336914\n",
      "Valid: MSELoss: 2318.395337\n",
      "===========================================================\n",
      "Train Epoch: 24 [0/17905 (0%)]  MSELoss: 1027.029053\n",
      "Train Epoch: 24 [3200/17905 (18%)]  MSELoss: 8788.139648\n",
      "Train Epoch: 24 [6400/17905 (36%)]  MSELoss: 7205.085938\n",
      "Train Epoch: 24 [9600/17905 (54%)]  MSELoss: 1228.628052\n",
      "Train Epoch: 24 [12800/17905 (71%)]  MSELoss: 9368.419922\n",
      "Train Epoch: 24 [16000/17905 (89%)]  MSELoss: 10097.654297\n",
      "Valid: MSELoss: 2214.974390\n",
      "===========================================================\n",
      "Train Epoch: 25 [0/17905 (0%)]  MSELoss: 1235.906616\n",
      "Train Epoch: 25 [3200/17905 (18%)]  MSELoss: 8372.606445\n",
      "Train Epoch: 25 [6400/17905 (36%)]  MSELoss: 8240.209961\n",
      "Train Epoch: 25 [9600/17905 (54%)]  MSELoss: 874.133118\n",
      "Train Epoch: 25 [12800/17905 (71%)]  MSELoss: 9316.928711\n",
      "Train Epoch: 25 [16000/17905 (89%)]  MSELoss: 10029.965820\n",
      "Valid: MSELoss: 2177.971240\n",
      "===========================================================\n",
      "Train Epoch: 26 [0/17905 (0%)]  MSELoss: 1334.608032\n",
      "Train Epoch: 26 [3200/17905 (18%)]  MSELoss: 8627.146484\n",
      "Train Epoch: 26 [6400/17905 (36%)]  MSELoss: 8700.033203\n",
      "Train Epoch: 26 [9600/17905 (54%)]  MSELoss: 775.033386\n",
      "Train Epoch: 26 [12800/17905 (71%)]  MSELoss: 8293.000000\n",
      "Train Epoch: 26 [16000/17905 (89%)]  MSELoss: 9826.190430\n",
      "Valid: MSELoss: 2143.503247\n",
      "===========================================================\n",
      "Train Epoch: 27 [0/17905 (0%)]  MSELoss: 1364.159546\n",
      "Train Epoch: 27 [3200/17905 (18%)]  MSELoss: 8940.468750\n",
      "Train Epoch: 27 [6400/17905 (36%)]  MSELoss: 8643.527344\n",
      "Train Epoch: 27 [9600/17905 (54%)]  MSELoss: 689.798706\n",
      "Train Epoch: 27 [12800/17905 (71%)]  MSELoss: 8461.903320\n",
      "Train Epoch: 27 [16000/17905 (89%)]  MSELoss: 9635.580078\n",
      "Valid: MSELoss: 2281.117114\n",
      "===========================================================\n",
      "Train Epoch: 28 [0/17905 (0%)]  MSELoss: 1115.928345\n",
      "Train Epoch: 28 [3200/17905 (18%)]  MSELoss: 8904.426758\n",
      "Train Epoch: 28 [6400/17905 (36%)]  MSELoss: 8686.623047\n",
      "Train Epoch: 28 [9600/17905 (54%)]  MSELoss: 692.887817\n",
      "Train Epoch: 28 [12800/17905 (71%)]  MSELoss: 8229.823242\n",
      "Train Epoch: 28 [16000/17905 (89%)]  MSELoss: 9830.733398\n",
      "Valid: MSELoss: 2195.619360\n",
      "===========================================================\n",
      "Train Epoch: 29 [0/17905 (0%)]  MSELoss: 1291.301880\n",
      "Train Epoch: 29 [3200/17905 (18%)]  MSELoss: 8568.230469\n",
      "Train Epoch: 29 [6400/17905 (36%)]  MSELoss: 8709.722656\n",
      "Train Epoch: 29 [9600/17905 (54%)]  MSELoss: 666.108704\n",
      "Train Epoch: 29 [12800/17905 (71%)]  MSELoss: 8422.025391\n",
      "Train Epoch: 29 [16000/17905 (89%)]  MSELoss: 9897.899414\n",
      "Valid: MSELoss: 2209.414795\n",
      "===========================================================\n",
      "Train Epoch: 30 [0/17905 (0%)]  MSELoss: 1221.505859\n",
      "Train Epoch: 30 [3200/17905 (18%)]  MSELoss: 8303.175781\n",
      "Train Epoch: 30 [6400/17905 (36%)]  MSELoss: 9133.481445\n",
      "Train Epoch: 30 [9600/17905 (54%)]  MSELoss: 672.072388\n",
      "Train Epoch: 30 [12800/17905 (71%)]  MSELoss: 7800.172852\n",
      "Train Epoch: 30 [16000/17905 (89%)]  MSELoss: 10307.375000\n",
      "Valid: MSELoss: 2180.318286\n",
      "===========================================================\n",
      "Train Epoch: 31 [0/17905 (0%)]  MSELoss: 1247.672363\n",
      "Train Epoch: 31 [3200/17905 (18%)]  MSELoss: 8452.949219\n",
      "Train Epoch: 31 [6400/17905 (36%)]  MSELoss: 8697.569336\n",
      "Train Epoch: 31 [9600/17905 (54%)]  MSELoss: 739.403931\n",
      "Train Epoch: 31 [12800/17905 (71%)]  MSELoss: 7878.001953\n",
      "Train Epoch: 31 [16000/17905 (89%)]  MSELoss: 9954.732422\n",
      "Valid: MSELoss: 2202.869189\n",
      "===========================================================\n",
      "Train Epoch: 32 [0/17905 (0%)]  MSELoss: 1189.403687\n",
      "Train Epoch: 32 [3200/17905 (18%)]  MSELoss: 8288.515625\n",
      "Train Epoch: 32 [6400/17905 (36%)]  MSELoss: 9039.984375\n",
      "Train Epoch: 32 [9600/17905 (54%)]  MSELoss: 680.211914\n",
      "Train Epoch: 32 [12800/17905 (71%)]  MSELoss: 7663.255371\n",
      "Train Epoch: 32 [16000/17905 (89%)]  MSELoss: 9895.887695\n",
      "Valid: MSELoss: 2207.434155\n",
      "===========================================================\n",
      "Train Epoch: 33 [0/17905 (0%)]  MSELoss: 1168.074219\n",
      "Train Epoch: 33 [3200/17905 (18%)]  MSELoss: 8434.628906\n",
      "Train Epoch: 33 [6400/17905 (36%)]  MSELoss: 9099.754883\n",
      "Train Epoch: 33 [9600/17905 (54%)]  MSELoss: 661.345276\n",
      "Train Epoch: 33 [12800/17905 (71%)]  MSELoss: 7586.540039\n",
      "Train Epoch: 33 [16000/17905 (89%)]  MSELoss: 9830.447266\n",
      "Valid: MSELoss: 2166.916919\n",
      "===========================================================\n",
      "Train Epoch: 34 [0/17905 (0%)]  MSELoss: 1300.580811\n",
      "Train Epoch: 34 [3200/17905 (18%)]  MSELoss: 8929.716797\n",
      "Train Epoch: 34 [6400/17905 (36%)]  MSELoss: 8841.298828\n",
      "Train Epoch: 34 [9600/17905 (54%)]  MSELoss: 674.145325\n",
      "Train Epoch: 34 [12800/17905 (71%)]  MSELoss: 7467.908203\n",
      "Train Epoch: 34 [16000/17905 (89%)]  MSELoss: 9910.961914\n",
      "Valid: MSELoss: 2185.955713\n",
      "===========================================================\n",
      "Train Epoch: 35 [0/17905 (0%)]  MSELoss: 1290.887207\n",
      "Train Epoch: 35 [3200/17905 (18%)]  MSELoss: 8342.084961\n",
      "Train Epoch: 35 [6400/17905 (36%)]  MSELoss: 8895.232422\n",
      "Train Epoch: 35 [9600/17905 (54%)]  MSELoss: 654.156921\n",
      "Train Epoch: 35 [12800/17905 (71%)]  MSELoss: 7174.349609\n",
      "Train Epoch: 35 [16000/17905 (89%)]  MSELoss: 9929.935547\n",
      "Valid: MSELoss: 2197.395190\n",
      "===========================================================\n",
      "Train Epoch: 36 [0/17905 (0%)]  MSELoss: 1240.859619\n",
      "Train Epoch: 36 [3200/17905 (18%)]  MSELoss: 8646.120117\n",
      "Train Epoch: 36 [6400/17905 (36%)]  MSELoss: 8768.439453\n",
      "Train Epoch: 36 [9600/17905 (54%)]  MSELoss: 651.630066\n",
      "Train Epoch: 36 [12800/17905 (71%)]  MSELoss: 7175.951660\n",
      "Train Epoch: 36 [16000/17905 (89%)]  MSELoss: 9987.038086\n",
      "Valid: MSELoss: 2225.900830\n",
      "===========================================================\n",
      "Train Epoch: 37 [0/17905 (0%)]  MSELoss: 1198.630493\n",
      "Train Epoch: 37 [3200/17905 (18%)]  MSELoss: 8450.100586\n",
      "Train Epoch: 37 [6400/17905 (36%)]  MSELoss: 8438.576172\n",
      "Train Epoch: 37 [9600/17905 (54%)]  MSELoss: 666.670227\n",
      "Train Epoch: 37 [12800/17905 (71%)]  MSELoss: 7060.756348\n",
      "Train Epoch: 37 [16000/17905 (89%)]  MSELoss: 9936.740234\n",
      "Valid: MSELoss: 2231.819849\n",
      "===========================================================\n",
      "Train Epoch: 38 [0/17905 (0%)]  MSELoss: 1210.683105\n",
      "Train Epoch: 38 [3200/17905 (18%)]  MSELoss: 8460.778320\n",
      "Train Epoch: 38 [6400/17905 (36%)]  MSELoss: 8396.075195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [9600/17905 (54%)]  MSELoss: 675.898193\n",
      "Train Epoch: 38 [12800/17905 (71%)]  MSELoss: 7067.342285\n",
      "Train Epoch: 38 [16000/17905 (89%)]  MSELoss: 9847.128906\n",
      "Valid: MSELoss: 2245.302222\n",
      "===========================================================\n",
      "Train Epoch: 39 [0/17905 (0%)]  MSELoss: 1191.368042\n",
      "Train Epoch: 39 [3200/17905 (18%)]  MSELoss: 8507.418945\n",
      "Train Epoch: 39 [6400/17905 (36%)]  MSELoss: 8414.120117\n",
      "Train Epoch: 39 [9600/17905 (54%)]  MSELoss: 669.659851\n",
      "Train Epoch: 39 [12800/17905 (71%)]  MSELoss: 6945.619141\n",
      "Train Epoch: 39 [16000/17905 (89%)]  MSELoss: 10104.437500\n",
      "Valid: MSELoss: 2254.716846\n",
      "===========================================================\n",
      "Train Epoch: 40 [0/17905 (0%)]  MSELoss: 1170.014404\n",
      "Train Epoch: 40 [3200/17905 (18%)]  MSELoss: 8587.698242\n",
      "Train Epoch: 40 [6400/17905 (36%)]  MSELoss: 8252.429688\n",
      "Train Epoch: 40 [9600/17905 (54%)]  MSELoss: 663.675110\n",
      "Train Epoch: 40 [12800/17905 (71%)]  MSELoss: 6895.569336\n",
      "Train Epoch: 40 [16000/17905 (89%)]  MSELoss: 9944.930664\n",
      "Valid: MSELoss: 2264.997070\n",
      "===========================================================\n",
      "Train Epoch: 41 [0/17905 (0%)]  MSELoss: 1177.614624\n",
      "Train Epoch: 41 [3200/17905 (18%)]  MSELoss: 8545.245117\n",
      "Train Epoch: 41 [6400/17905 (36%)]  MSELoss: 8256.305664\n",
      "Train Epoch: 41 [9600/17905 (54%)]  MSELoss: 662.015869\n",
      "Train Epoch: 41 [12800/17905 (71%)]  MSELoss: 6894.603516\n",
      "Train Epoch: 41 [16000/17905 (89%)]  MSELoss: 10064.708008\n",
      "Valid: MSELoss: 2272.822363\n",
      "===========================================================\n",
      "Train Epoch: 42 [0/17905 (0%)]  MSELoss: 1157.156494\n",
      "Train Epoch: 42 [3200/17905 (18%)]  MSELoss: 8550.843750\n",
      "Train Epoch: 42 [6400/17905 (36%)]  MSELoss: 8289.022461\n",
      "Train Epoch: 42 [9600/17905 (54%)]  MSELoss: 657.605103\n",
      "Train Epoch: 42 [12800/17905 (71%)]  MSELoss: 6903.156738\n",
      "Train Epoch: 42 [16000/17905 (89%)]  MSELoss: 10943.426758\n",
      "Valid: MSELoss: 2284.768311\n",
      "===========================================================\n",
      "Train Epoch: 43 [0/17905 (0%)]  MSELoss: 1158.420776\n",
      "Train Epoch: 43 [3200/17905 (18%)]  MSELoss: 8508.153320\n",
      "Train Epoch: 43 [6400/17905 (36%)]  MSELoss: 8023.038086\n",
      "Train Epoch: 43 [9600/17905 (54%)]  MSELoss: 663.996094\n",
      "Train Epoch: 43 [12800/17905 (71%)]  MSELoss: 6736.605469\n",
      "Train Epoch: 43 [16000/17905 (89%)]  MSELoss: 10984.105469\n",
      "Valid: MSELoss: 2284.191479\n",
      "===========================================================\n",
      "Train Epoch: 44 [0/17905 (0%)]  MSELoss: 1126.929077\n",
      "Train Epoch: 44 [3200/17905 (18%)]  MSELoss: 8480.189453\n",
      "Train Epoch: 44 [6400/17905 (36%)]  MSELoss: 8380.590820\n",
      "Train Epoch: 44 [9600/17905 (54%)]  MSELoss: 653.640930\n",
      "Train Epoch: 44 [12800/17905 (71%)]  MSELoss: 6748.806152\n",
      "Train Epoch: 44 [16000/17905 (89%)]  MSELoss: 11262.888672\n",
      "Valid: MSELoss: 2230.797119\n",
      "===========================================================\n",
      "Train Epoch: 45 [0/17905 (0%)]  MSELoss: 1185.169922\n",
      "Train Epoch: 45 [3200/17905 (18%)]  MSELoss: 8261.208984\n",
      "Train Epoch: 45 [6400/17905 (36%)]  MSELoss: 8497.436523\n",
      "Train Epoch: 45 [9600/17905 (54%)]  MSELoss: 658.868835\n",
      "Train Epoch: 45 [12800/17905 (71%)]  MSELoss: 6786.439941\n",
      "Train Epoch: 45 [16000/17905 (89%)]  MSELoss: 11038.743164\n",
      "Valid: MSELoss: 2233.115332\n",
      "===========================================================\n",
      "Train Epoch: 46 [0/17905 (0%)]  MSELoss: 1152.847168\n",
      "Train Epoch: 46 [3200/17905 (18%)]  MSELoss: 8289.816406\n",
      "Train Epoch: 46 [6400/17905 (36%)]  MSELoss: 8440.243164\n",
      "Train Epoch: 46 [9600/17905 (54%)]  MSELoss: 645.426086\n",
      "Train Epoch: 46 [12800/17905 (71%)]  MSELoss: 6686.456543\n",
      "Train Epoch: 46 [16000/17905 (89%)]  MSELoss: 10954.902344\n",
      "Valid: MSELoss: 2235.809497\n",
      "===========================================================\n",
      "Train Epoch: 47 [0/17905 (0%)]  MSELoss: 1170.972656\n",
      "Train Epoch: 47 [3200/17905 (18%)]  MSELoss: 8327.888672\n",
      "Train Epoch: 47 [6400/17905 (36%)]  MSELoss: 8248.198242\n",
      "Train Epoch: 47 [9600/17905 (54%)]  MSELoss: 650.493652\n",
      "Train Epoch: 47 [12800/17905 (71%)]  MSELoss: 6574.408203\n",
      "Train Epoch: 47 [16000/17905 (89%)]  MSELoss: 10984.769531\n",
      "Valid: MSELoss: 2238.561987\n",
      "===========================================================\n",
      "Train Epoch: 48 [0/17905 (0%)]  MSELoss: 1208.593384\n",
      "Train Epoch: 48 [3200/17905 (18%)]  MSELoss: 8337.095703\n",
      "Train Epoch: 48 [6400/17905 (36%)]  MSELoss: 8120.592773\n",
      "Train Epoch: 48 [9600/17905 (54%)]  MSELoss: 653.012268\n",
      "Train Epoch: 48 [12800/17905 (71%)]  MSELoss: 6541.347168\n",
      "Train Epoch: 48 [16000/17905 (89%)]  MSELoss: 11019.137695\n",
      "Valid: MSELoss: 2240.222754\n",
      "===========================================================\n",
      "Train Epoch: 49 [0/17905 (0%)]  MSELoss: 1191.998901\n",
      "Train Epoch: 49 [3200/17905 (18%)]  MSELoss: 8368.760742\n",
      "Train Epoch: 49 [6400/17905 (36%)]  MSELoss: 7925.929688\n",
      "Train Epoch: 49 [9600/17905 (54%)]  MSELoss: 650.994934\n",
      "Train Epoch: 49 [12800/17905 (71%)]  MSELoss: 6551.339355\n",
      "Train Epoch: 49 [16000/17905 (89%)]  MSELoss: 11174.881836\n",
      "Valid: MSELoss: 2239.359668\n",
      "===========================================================\n",
      "Train Epoch: 50 [0/17905 (0%)]  MSELoss: 1203.025513\n",
      "Train Epoch: 50 [3200/17905 (18%)]  MSELoss: 8331.228516\n",
      "Train Epoch: 50 [6400/17905 (36%)]  MSELoss: 7919.328125\n",
      "Train Epoch: 50 [9600/17905 (54%)]  MSELoss: 647.886536\n",
      "Train Epoch: 50 [12800/17905 (71%)]  MSELoss: 6481.248535\n",
      "Train Epoch: 50 [16000/17905 (89%)]  MSELoss: 11440.587891\n",
      "Valid: MSELoss: 2250.418481\n",
      "===========================================================\n",
      "Train Epoch: 51 [0/17905 (0%)]  MSELoss: 1201.416870\n",
      "Train Epoch: 51 [3200/17905 (18%)]  MSELoss: 8281.426758\n",
      "Train Epoch: 51 [6400/17905 (36%)]  MSELoss: 7789.634766\n",
      "Train Epoch: 51 [9600/17905 (54%)]  MSELoss: 650.546753\n",
      "Train Epoch: 51 [12800/17905 (71%)]  MSELoss: 6442.807129\n",
      "Train Epoch: 51 [16000/17905 (89%)]  MSELoss: 11515.491211\n",
      "Valid: MSELoss: 2255.771948\n",
      "===========================================================\n",
      "Train Epoch: 52 [0/17905 (0%)]  MSELoss: 1185.784546\n",
      "Train Epoch: 52 [3200/17905 (18%)]  MSELoss: 8344.213867\n",
      "Train Epoch: 52 [6400/17905 (36%)]  MSELoss: 7593.166504\n",
      "Train Epoch: 52 [9600/17905 (54%)]  MSELoss: 640.609192\n",
      "Train Epoch: 52 [12800/17905 (71%)]  MSELoss: 6340.850586\n",
      "Train Epoch: 52 [16000/17905 (89%)]  MSELoss: 11484.343750\n",
      "Valid: MSELoss: 2261.176074\n",
      "===========================================================\n",
      "Train Epoch: 53 [0/17905 (0%)]  MSELoss: 1186.151001\n",
      "Train Epoch: 53 [3200/17905 (18%)]  MSELoss: 8402.642578\n",
      "Train Epoch: 53 [6400/17905 (36%)]  MSELoss: 7493.124023\n",
      "Train Epoch: 53 [9600/17905 (54%)]  MSELoss: 633.151306\n",
      "Train Epoch: 53 [12800/17905 (71%)]  MSELoss: 6244.762207\n",
      "Train Epoch: 53 [16000/17905 (89%)]  MSELoss: 11530.103516\n",
      "Valid: MSELoss: 2260.421606\n",
      "===========================================================\n",
      "Train Epoch: 54 [0/17905 (0%)]  MSELoss: 1191.471069\n",
      "Train Epoch: 54 [3200/17905 (18%)]  MSELoss: 8328.095703\n",
      "Train Epoch: 54 [6400/17905 (36%)]  MSELoss: 7422.623535\n",
      "Train Epoch: 54 [9600/17905 (54%)]  MSELoss: 644.928284\n",
      "Train Epoch: 54 [12800/17905 (71%)]  MSELoss: 6228.194824\n",
      "Train Epoch: 54 [16000/17905 (89%)]  MSELoss: 11542.459961\n",
      "Valid: MSELoss: 2261.646021\n",
      "===========================================================\n",
      "Train Epoch: 55 [0/17905 (0%)]  MSELoss: 1175.127319\n",
      "Train Epoch: 55 [3200/17905 (18%)]  MSELoss: 8347.727539\n",
      "Train Epoch: 55 [6400/17905 (36%)]  MSELoss: 7300.395996\n",
      "Train Epoch: 55 [9600/17905 (54%)]  MSELoss: 629.865295\n",
      "Train Epoch: 55 [12800/17905 (71%)]  MSELoss: 6204.885254\n",
      "Train Epoch: 55 [16000/17905 (89%)]  MSELoss: 11538.410156\n",
      "Valid: MSELoss: 2262.182129\n",
      "===========================================================\n",
      "Train Epoch: 56 [0/17905 (0%)]  MSELoss: 1195.725586\n",
      "Train Epoch: 56 [3200/17905 (18%)]  MSELoss: 8344.665039\n",
      "Train Epoch: 56 [6400/17905 (36%)]  MSELoss: 7154.040527\n",
      "Train Epoch: 56 [9600/17905 (54%)]  MSELoss: 632.270447\n",
      "Train Epoch: 56 [12800/17905 (71%)]  MSELoss: 6158.823730\n",
      "Train Epoch: 56 [16000/17905 (89%)]  MSELoss: 11631.375000\n",
      "Valid: MSELoss: 2262.652466\n",
      "===========================================================\n",
      "Train Epoch: 57 [0/17905 (0%)]  MSELoss: 1211.771606\n",
      "Train Epoch: 57 [3200/17905 (18%)]  MSELoss: 8313.125000\n",
      "Train Epoch: 57 [6400/17905 (36%)]  MSELoss: 7037.890625\n",
      "Train Epoch: 57 [9600/17905 (54%)]  MSELoss: 624.472534\n",
      "Train Epoch: 57 [12800/17905 (71%)]  MSELoss: 6139.462891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [16000/17905 (89%)]  MSELoss: 11712.053711\n",
      "Valid: MSELoss: 2262.981348\n",
      "===========================================================\n",
      "Train Epoch: 58 [0/17905 (0%)]  MSELoss: 1180.188110\n",
      "Train Epoch: 58 [3200/17905 (18%)]  MSELoss: 8358.610352\n",
      "Train Epoch: 58 [6400/17905 (36%)]  MSELoss: 6927.455078\n",
      "Train Epoch: 58 [9600/17905 (54%)]  MSELoss: 631.702148\n",
      "Train Epoch: 58 [12800/17905 (71%)]  MSELoss: 6126.428223\n",
      "Train Epoch: 58 [16000/17905 (89%)]  MSELoss: 11685.963867\n",
      "Valid: MSELoss: 2265.136255\n",
      "===========================================================\n",
      "Train Epoch: 59 [0/17905 (0%)]  MSELoss: 1180.869751\n",
      "Train Epoch: 59 [3200/17905 (18%)]  MSELoss: 8306.153320\n",
      "Train Epoch: 59 [6400/17905 (36%)]  MSELoss: 6644.112793\n",
      "Train Epoch: 59 [9600/17905 (54%)]  MSELoss: 616.934753\n",
      "Train Epoch: 59 [12800/17905 (71%)]  MSELoss: 6072.867188\n",
      "Train Epoch: 59 [16000/17905 (89%)]  MSELoss: 11777.922852\n",
      "Valid: MSELoss: 2267.188525\n",
      "===========================================================\n",
      "Train Epoch: 60 [0/17905 (0%)]  MSELoss: 1165.160767\n",
      "Train Epoch: 60 [3200/17905 (18%)]  MSELoss: 8264.328125\n",
      "Train Epoch: 60 [6400/17905 (36%)]  MSELoss: 6492.632812\n",
      "Train Epoch: 60 [9600/17905 (54%)]  MSELoss: 625.941833\n",
      "Train Epoch: 60 [12800/17905 (71%)]  MSELoss: 6091.319824\n",
      "Train Epoch: 60 [16000/17905 (89%)]  MSELoss: 11818.627930\n",
      "Valid: MSELoss: 2271.755811\n",
      "===========================================================\n",
      "Train Epoch: 61 [0/17905 (0%)]  MSELoss: 1189.391235\n",
      "Train Epoch: 61 [3200/17905 (18%)]  MSELoss: 8213.588867\n",
      "Train Epoch: 61 [6400/17905 (36%)]  MSELoss: 6345.541504\n",
      "Train Epoch: 61 [9600/17905 (54%)]  MSELoss: 625.267029\n",
      "Train Epoch: 61 [12800/17905 (71%)]  MSELoss: 6005.801758\n",
      "Train Epoch: 61 [16000/17905 (89%)]  MSELoss: 11907.479492\n",
      "Valid: MSELoss: 2273.093677\n",
      "===========================================================\n",
      "Train Epoch: 62 [0/17905 (0%)]  MSELoss: 1184.112549\n",
      "Train Epoch: 62 [3200/17905 (18%)]  MSELoss: 8308.324219\n",
      "Train Epoch: 62 [6400/17905 (36%)]  MSELoss: 6109.768066\n",
      "Train Epoch: 62 [9600/17905 (54%)]  MSELoss: 605.356018\n",
      "Train Epoch: 62 [12800/17905 (71%)]  MSELoss: 6065.713867\n",
      "Train Epoch: 62 [16000/17905 (89%)]  MSELoss: 11837.160156\n",
      "Valid: MSELoss: 2273.980249\n",
      "===========================================================\n",
      "Train Epoch: 63 [0/17905 (0%)]  MSELoss: 1177.762329\n",
      "Train Epoch: 63 [3200/17905 (18%)]  MSELoss: 8246.592773\n",
      "Train Epoch: 63 [6400/17905 (36%)]  MSELoss: 5881.352539\n",
      "Train Epoch: 63 [9600/17905 (54%)]  MSELoss: 608.432739\n",
      "Train Epoch: 63 [12800/17905 (71%)]  MSELoss: 6059.350098\n",
      "Train Epoch: 63 [16000/17905 (89%)]  MSELoss: 11832.275391\n",
      "Valid: MSELoss: 2275.455225\n",
      "===========================================================\n",
      "Train Epoch: 64 [0/17905 (0%)]  MSELoss: 1182.239380\n",
      "Train Epoch: 64 [3200/17905 (18%)]  MSELoss: 8187.866211\n",
      "Train Epoch: 64 [6400/17905 (36%)]  MSELoss: 5741.511230\n",
      "Train Epoch: 64 [9600/17905 (54%)]  MSELoss: 600.941956\n",
      "Train Epoch: 64 [12800/17905 (71%)]  MSELoss: 5879.200684\n",
      "Train Epoch: 64 [16000/17905 (89%)]  MSELoss: 11843.769531\n",
      "Valid: MSELoss: 2275.616431\n",
      "===========================================================\n",
      "Train Epoch: 65 [0/17905 (0%)]  MSELoss: 1190.979004\n",
      "Train Epoch: 65 [3200/17905 (18%)]  MSELoss: 8184.069336\n",
      "Train Epoch: 65 [6400/17905 (36%)]  MSELoss: 5634.725098\n",
      "Train Epoch: 65 [9600/17905 (54%)]  MSELoss: 599.749451\n",
      "Train Epoch: 65 [12800/17905 (71%)]  MSELoss: 5989.409668\n",
      "Train Epoch: 65 [16000/17905 (89%)]  MSELoss: 11975.466797\n",
      "Valid: MSELoss: 2275.436914\n",
      "===========================================================\n",
      "Train Epoch: 66 [0/17905 (0%)]  MSELoss: 1204.828613\n",
      "Train Epoch: 66 [3200/17905 (18%)]  MSELoss: 8190.217285\n",
      "Train Epoch: 66 [6400/17905 (36%)]  MSELoss: 5546.910645\n",
      "Train Epoch: 66 [9600/17905 (54%)]  MSELoss: 601.940857\n",
      "Train Epoch: 66 [12800/17905 (71%)]  MSELoss: 5987.867188\n",
      "Train Epoch: 66 [16000/17905 (89%)]  MSELoss: 11904.613281\n",
      "Valid: MSELoss: 2274.022681\n",
      "===========================================================\n",
      "Train Epoch: 67 [0/17905 (0%)]  MSELoss: 1172.327637\n",
      "Train Epoch: 67 [3200/17905 (18%)]  MSELoss: 8156.433105\n",
      "Train Epoch: 67 [6400/17905 (36%)]  MSELoss: 5412.545410\n",
      "Train Epoch: 67 [9600/17905 (54%)]  MSELoss: 588.096497\n",
      "Train Epoch: 67 [12800/17905 (71%)]  MSELoss: 5918.279785\n",
      "Train Epoch: 67 [16000/17905 (89%)]  MSELoss: 11968.764648\n",
      "Valid: MSELoss: 2273.933911\n",
      "===========================================================\n",
      "Train Epoch: 68 [0/17905 (0%)]  MSELoss: 1172.023193\n",
      "Train Epoch: 68 [3200/17905 (18%)]  MSELoss: 8132.785645\n",
      "Train Epoch: 68 [6400/17905 (36%)]  MSELoss: 5383.880859\n",
      "Train Epoch: 68 [9600/17905 (54%)]  MSELoss: 579.086975\n",
      "Train Epoch: 68 [12800/17905 (71%)]  MSELoss: 5930.935547\n",
      "Train Epoch: 68 [16000/17905 (89%)]  MSELoss: 11928.032227\n",
      "Valid: MSELoss: 2273.478418\n",
      "===========================================================\n",
      "Train Epoch: 69 [0/17905 (0%)]  MSELoss: 1190.146606\n",
      "Train Epoch: 69 [3200/17905 (18%)]  MSELoss: 8103.125000\n",
      "Train Epoch: 69 [6400/17905 (36%)]  MSELoss: 5185.415039\n",
      "Train Epoch: 69 [9600/17905 (54%)]  MSELoss: 581.448853\n",
      "Train Epoch: 69 [12800/17905 (71%)]  MSELoss: 5900.836426\n",
      "Train Epoch: 69 [16000/17905 (89%)]  MSELoss: 11882.629883\n",
      "Valid: MSELoss: 2275.409033\n",
      "===========================================================\n",
      "Train Epoch: 70 [0/17905 (0%)]  MSELoss: 1189.509521\n",
      "Train Epoch: 70 [3200/17905 (18%)]  MSELoss: 8184.114746\n",
      "Train Epoch: 70 [6400/17905 (36%)]  MSELoss: 5148.113281\n",
      "Train Epoch: 70 [9600/17905 (54%)]  MSELoss: 574.432373\n",
      "Train Epoch: 70 [12800/17905 (71%)]  MSELoss: 5815.128418\n",
      "Train Epoch: 70 [16000/17905 (89%)]  MSELoss: 11940.942383\n",
      "Valid: MSELoss: 2277.216748\n",
      "===========================================================\n",
      "Train Epoch: 71 [0/17905 (0%)]  MSELoss: 1184.825562\n",
      "Train Epoch: 71 [3200/17905 (18%)]  MSELoss: 8136.286621\n",
      "Train Epoch: 71 [6400/17905 (36%)]  MSELoss: 4997.379395\n",
      "Train Epoch: 71 [9600/17905 (54%)]  MSELoss: 557.896179\n",
      "Train Epoch: 71 [12800/17905 (71%)]  MSELoss: 5807.124023\n",
      "Train Epoch: 71 [16000/17905 (89%)]  MSELoss: 11913.067383\n",
      "Valid: MSELoss: 2277.188867\n",
      "===========================================================\n",
      "Train Epoch: 72 [0/17905 (0%)]  MSELoss: 1179.852173\n",
      "Train Epoch: 72 [3200/17905 (18%)]  MSELoss: 8079.436035\n",
      "Train Epoch: 72 [6400/17905 (36%)]  MSELoss: 5082.243164\n",
      "Train Epoch: 72 [9600/17905 (54%)]  MSELoss: 560.585815\n",
      "Train Epoch: 72 [12800/17905 (71%)]  MSELoss: 5894.139648\n",
      "Train Epoch: 72 [16000/17905 (89%)]  MSELoss: 11987.508789\n",
      "Valid: MSELoss: 2279.525879\n",
      "===========================================================\n",
      "Train Epoch: 73 [0/17905 (0%)]  MSELoss: 1175.254028\n",
      "Train Epoch: 73 [3200/17905 (18%)]  MSELoss: 8041.802246\n",
      "Train Epoch: 73 [6400/17905 (36%)]  MSELoss: 5068.061523\n",
      "Train Epoch: 73 [9600/17905 (54%)]  MSELoss: 553.368958\n",
      "Train Epoch: 73 [12800/17905 (71%)]  MSELoss: 5815.517578\n",
      "Train Epoch: 73 [16000/17905 (89%)]  MSELoss: 12017.375977\n",
      "Valid: MSELoss: 2281.729565\n",
      "===========================================================\n",
      "Train Epoch: 74 [0/17905 (0%)]  MSELoss: 1169.644775\n",
      "Train Epoch: 74 [3200/17905 (18%)]  MSELoss: 8104.900879\n",
      "Train Epoch: 74 [6400/17905 (36%)]  MSELoss: 4965.053223\n",
      "Train Epoch: 74 [9600/17905 (54%)]  MSELoss: 546.995422\n",
      "Train Epoch: 74 [12800/17905 (71%)]  MSELoss: 5719.168457\n",
      "Train Epoch: 74 [16000/17905 (89%)]  MSELoss: 11986.472656\n",
      "Valid: MSELoss: 2283.490942\n",
      "===========================================================\n",
      "Train Epoch: 75 [0/17905 (0%)]  MSELoss: 1174.678345\n",
      "Train Epoch: 75 [3200/17905 (18%)]  MSELoss: 8006.003418\n",
      "Train Epoch: 75 [6400/17905 (36%)]  MSELoss: 4871.551270\n",
      "Train Epoch: 75 [9600/17905 (54%)]  MSELoss: 538.114380\n",
      "Train Epoch: 75 [12800/17905 (71%)]  MSELoss: 5776.132324\n",
      "Train Epoch: 75 [16000/17905 (89%)]  MSELoss: 11974.997070\n",
      "Valid: MSELoss: 2286.102734\n",
      "===========================================================\n",
      "Train Epoch: 76 [0/17905 (0%)]  MSELoss: 1180.078735\n",
      "Train Epoch: 76 [3200/17905 (18%)]  MSELoss: 7982.236328\n",
      "Train Epoch: 76 [6400/17905 (36%)]  MSELoss: 4907.104004\n",
      "Train Epoch: 76 [9600/17905 (54%)]  MSELoss: 517.774292\n",
      "Train Epoch: 76 [12800/17905 (71%)]  MSELoss: 5815.019531\n",
      "Train Epoch: 76 [16000/17905 (89%)]  MSELoss: 11988.054688\n",
      "Valid: MSELoss: 2288.599194\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [0/17905 (0%)]  MSELoss: 1185.954224\n",
      "Train Epoch: 77 [3200/17905 (18%)]  MSELoss: 8025.965332\n",
      "Train Epoch: 77 [6400/17905 (36%)]  MSELoss: 4940.083984\n",
      "Train Epoch: 77 [9600/17905 (54%)]  MSELoss: 510.783112\n",
      "Train Epoch: 77 [12800/17905 (71%)]  MSELoss: 5803.155762\n",
      "Train Epoch: 77 [16000/17905 (89%)]  MSELoss: 11978.988281\n",
      "Valid: MSELoss: 2290.058984\n",
      "===========================================================\n",
      "Train Epoch: 78 [0/17905 (0%)]  MSELoss: 1150.564331\n",
      "Train Epoch: 78 [3200/17905 (18%)]  MSELoss: 8001.848145\n",
      "Train Epoch: 78 [6400/17905 (36%)]  MSELoss: 4894.295898\n",
      "Train Epoch: 78 [9600/17905 (54%)]  MSELoss: 478.191528\n",
      "Train Epoch: 78 [12800/17905 (71%)]  MSELoss: 5782.283691\n",
      "Train Epoch: 78 [16000/17905 (89%)]  MSELoss: 11903.603516\n",
      "Valid: MSELoss: 2292.075757\n",
      "===========================================================\n",
      "Train Epoch: 79 [0/17905 (0%)]  MSELoss: 1184.574463\n",
      "Train Epoch: 79 [3200/17905 (18%)]  MSELoss: 8031.180664\n",
      "Train Epoch: 79 [6400/17905 (36%)]  MSELoss: 4803.795898\n",
      "Train Epoch: 79 [9600/17905 (54%)]  MSELoss: 426.454346\n",
      "Train Epoch: 79 [12800/17905 (71%)]  MSELoss: 5756.650879\n",
      "Train Epoch: 79 [16000/17905 (89%)]  MSELoss: 11882.328125\n",
      "Valid: MSELoss: 2292.642578\n",
      "===========================================================\n",
      "Train Epoch: 80 [0/17905 (0%)]  MSELoss: 1166.973511\n",
      "Train Epoch: 80 [3200/17905 (18%)]  MSELoss: 7945.561035\n",
      "Train Epoch: 80 [6400/17905 (36%)]  MSELoss: 4849.727539\n",
      "Train Epoch: 80 [9600/17905 (54%)]  MSELoss: 336.620178\n",
      "Train Epoch: 80 [12800/17905 (71%)]  MSELoss: 5718.169434\n",
      "Train Epoch: 80 [16000/17905 (89%)]  MSELoss: 11852.856445\n",
      "Valid: MSELoss: 2291.279224\n",
      "===========================================================\n",
      "Train Epoch: 81 [0/17905 (0%)]  MSELoss: 1166.037720\n",
      "Train Epoch: 81 [3200/17905 (18%)]  MSELoss: 7957.592285\n",
      "Train Epoch: 81 [6400/17905 (36%)]  MSELoss: 4811.906738\n",
      "Train Epoch: 81 [9600/17905 (54%)]  MSELoss: 322.406403\n",
      "Train Epoch: 81 [12800/17905 (71%)]  MSELoss: 5744.025879\n",
      "Train Epoch: 81 [16000/17905 (89%)]  MSELoss: 11920.103516\n",
      "Valid: MSELoss: 2294.556641\n",
      "===========================================================\n",
      "Train Epoch: 82 [0/17905 (0%)]  MSELoss: 1191.450073\n",
      "Train Epoch: 82 [3200/17905 (18%)]  MSELoss: 7901.496582\n",
      "Train Epoch: 82 [6400/17905 (36%)]  MSELoss: 4774.801270\n",
      "Train Epoch: 82 [9600/17905 (54%)]  MSELoss: 332.269897\n",
      "Train Epoch: 82 [12800/17905 (71%)]  MSELoss: 5746.454102\n",
      "Train Epoch: 82 [16000/17905 (89%)]  MSELoss: 11916.247070\n",
      "Valid: MSELoss: 2300.885522\n",
      "===========================================================\n",
      "Train Epoch: 83 [0/17905 (0%)]  MSELoss: 1171.541992\n",
      "Train Epoch: 83 [3200/17905 (18%)]  MSELoss: 7911.024414\n",
      "Train Epoch: 83 [6400/17905 (36%)]  MSELoss: 4781.079102\n",
      "Train Epoch: 83 [9600/17905 (54%)]  MSELoss: 338.341705\n",
      "Train Epoch: 83 [12800/17905 (71%)]  MSELoss: 5744.774414\n",
      "Train Epoch: 83 [16000/17905 (89%)]  MSELoss: 11897.409180\n",
      "Valid: MSELoss: 2305.320703\n",
      "===========================================================\n",
      "Train Epoch: 84 [0/17905 (0%)]  MSELoss: 1151.775146\n",
      "Train Epoch: 84 [3200/17905 (18%)]  MSELoss: 7959.199707\n",
      "Train Epoch: 84 [6400/17905 (36%)]  MSELoss: 4791.760254\n",
      "Train Epoch: 84 [9600/17905 (54%)]  MSELoss: 339.827576\n",
      "Train Epoch: 84 [12800/17905 (71%)]  MSELoss: 5742.228516\n",
      "Train Epoch: 84 [16000/17905 (89%)]  MSELoss: 11815.798828\n",
      "Valid: MSELoss: 2310.745752\n",
      "===========================================================\n",
      "Train Epoch: 85 [0/17905 (0%)]  MSELoss: 1149.954712\n",
      "Train Epoch: 85 [3200/17905 (18%)]  MSELoss: 7899.709473\n",
      "Train Epoch: 85 [6400/17905 (36%)]  MSELoss: 4714.574707\n",
      "Train Epoch: 85 [9600/17905 (54%)]  MSELoss: 351.268433\n",
      "Train Epoch: 85 [12800/17905 (71%)]  MSELoss: 5703.964355\n",
      "Train Epoch: 85 [16000/17905 (89%)]  MSELoss: 11894.419922\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Detector')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=256, metavar='N',\n",
    "                        help='input batch size for testing (default: 256)')\n",
    "    parser.add_argument('--predict_batch_size', type=int, default=1, metavar='N',\n",
    "                        help='input batch size for predict (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=50, metavar='N',\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=10, metavar='S',\n",
    "                        help='random seed (default: 10)')\n",
    "    parser.add_argument('--log_interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save_model', action='store_true', default=False,\n",
    "                        help='save the current Model')\n",
    "    parser.add_argument('--save_directory', type=str, default='trained_models',\n",
    "                        help='learnt models are saving here')\n",
    "    parser.add_argument('--phase', type=str, default='Train',   # Train/train, Predict/predict, Finetune/finetune\n",
    "                        help='training, predicting or finetuning')\n",
    "    parser.add_argument('--number', type=int, default=0,\n",
    "                        help='which model to use')\n",
    "    parser.add_argument('--idx', type=int, default=0,\n",
    "                        help='which sample to predict')\n",
    "    args = parser.parse_args(['--batch_size=64',\n",
    "                              '--test_batch_size=2048',\n",
    "                              '--predict_batch_size=1',\n",
    "                              '--epochs=101',\n",
    "                              '--lr=0.00001',\n",
    "                              '--momentum=0.5',\n",
    "                              '--cuda',\n",
    "                              '--seed=1',\n",
    "                              '--log_interval=50',\n",
    "                              '--save_model',\n",
    "                              '--save_directory=trained_models_2',\n",
    "                              '--number=10',\n",
    "                              '--idx=150',\n",
    "                              '--phase=train'])\n",
    "    ##############################################################################################################\n",
    "    start = time.time()\n",
    "    train_losses, valid_losses = main(args)\n",
    "    end = time.time()\n",
    "    print('耗时：{}s'.format(end - start))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:33:14.027759Z",
     "start_time": "2020-01-15T03:33:12.726777Z"
    }
   },
   "outputs": [],
   "source": [
    "#读数据\n",
    "df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "data = df.values\n",
    "data[:,4] /= 10000\n",
    "#划分样本集\n",
    "trsf = transforms.Compose([ToTensor()])\n",
    "train_set = AqiDataset(data[:18000], trsf)\n",
    "test_set = AqiDataset(data[18000:27000], trsf)\n",
    "val_set = AqiDataset(data[27000:], trsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T03:33:14.040351Z",
     "start_time": "2020-01-15T03:33:14.030103Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[17.0000, 11.8400, -6.4500,  ...,  0.0000,  0.0000, -0.5100],\n",
       "         [16.0000, 11.7400, -6.2700,  ...,  0.0000,  0.0000, -0.7100],\n",
       "         [16.1100, 11.9900, -6.5600,  ...,  0.0000,  0.0000, -0.5700],\n",
       "         ...,\n",
       "         [ 0.0000, 17.0400, -4.5400,  ...,  0.0000,  0.0000, -0.8800],\n",
       "         [ 0.0000, 15.6900, -3.3400,  ...,  0.0000,  0.0000, -1.3200],\n",
       "         [ 0.0000, 15.3300, -2.6400,  ...,  0.0000,  0.0000, -1.2100]]),\n",
       " 'y': tensor([28.3800, 29.4600, 30.5400, 31.6200, 32.6900, 33.7700, 34.8500, 35.9200,\n",
       "         37.0000, 38.0800, 39.1500, 40.2300, 41.3100, 42.3800, 43.4600, 44.5400,\n",
       "         45.6200, 46.6900, 47.7700, 48.8500, 49.9200, 51.0000, 52.0800, 53.1500,\n",
       "         54.2300, 55.3100, 56.3800, 57.4600, 58.5400, 59.6200, 60.6900, 61.7700,\n",
       "         62.8500, 63.9200, 65.0000, 72.0000, 79.0000, 86.0000, 77.6700, 69.3300,\n",
       "         61.0000, 58.6700, 56.3300, 54.0000, 51.4700, 48.9300, 46.4000, 43.8700,\n",
       "         41.3300, 38.8000, 36.2700, 33.7300, 31.2000, 28.6700, 26.1300, 23.6000,\n",
       "         21.0700, 18.5300, 16.0000, 15.6700, 15.3300, 15.0000, 18.0000, 21.0000,\n",
       "         24.0000, 23.6700, 23.3300, 23.0000, 25.3300, 27.6700, 30.0000, 33.3300])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.3.1",
   "language": "python",
   "name": "torch-1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
