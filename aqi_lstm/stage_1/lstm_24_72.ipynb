{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:31:00.403838Z",
     "start_time": "2020-01-15T08:30:56.511918Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "from torch.utils.data import  DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:31:00.415867Z",
     "start_time": "2020-01-15T08:31:00.406967Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_parameters_init(model):\n",
    "    '''\n",
    "    kaiming init\n",
    "    '''\n",
    "    for p in model.parameters():\n",
    "        if len(p.shape) >= 2:\n",
    "            nn.init.kaiming_normal_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:04:11.567593Z",
     "start_time": "2020-01-15T10:04:11.560963Z"
    }
   },
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    '''\n",
    "    只输入一个aqi，其他置0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(NetWork,self).__init__()\n",
    "        self.lstm = nn.LSTM(24, 144, 1, batch_first= True)\n",
    "        self.linear_1 = nn.Linear(144, 72)\n",
    "        self.linear_2 = nn.Linear(72, 1)\n",
    "        self.relu = nn.PReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.bn = nn.BatchNorm1d(96)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x,(h_1,c_1) = self.lstm(x)\n",
    "        x = x[:,24:,:]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:31:00.509135Z",
     "start_time": "2020-01-15T08:31:00.500078Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''\n",
    "    transform sample to tensor\n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        sample['x'] = torch.from_numpy(sample['x']).float()\n",
    "        sample['y'] = torch.from_numpy(sample['y']).float()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:31:00.524700Z",
     "start_time": "2020-01-15T08:31:00.511640Z"
    }
   },
   "outputs": [],
   "source": [
    "class AqiDataset():\n",
    "    '''\n",
    "    用于获取aqi训练与测试数据\n",
    "    '''\n",
    "    def __init__(self, data, transforms= None):\n",
    "        '''\n",
    "        data: samples of ndarray from csv\n",
    "        '''\n",
    "        self.data = data.copy()\n",
    "        #前24气象要素用不到，只取aqi\n",
    "        #后面71个取不到\n",
    "        self.size = len(data) - 71 - 24\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self):\n",
    "        print('使用__getitem__(idx)获取数据')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        定义了__getitem__魔法函数，该类就可以下标操作了：[]\n",
    "        '''\n",
    "        #历史24时刻数据\n",
    "        history = self.data[idx : idx + 24].copy()\n",
    "        #未来72时刻数据（不包括AQI）\n",
    "        future = self.data[idx + 24 : idx + 24 + 72].copy()\n",
    "        future[:,0] = 0\n",
    "        #合并\n",
    "        h_f = np.r_[history, future]\n",
    "        #取各个时刻的实测值\n",
    "        lables = self.data[idx + 24 : idx + 24 + 72, 0].copy()\n",
    "        #进行必要的变换\n",
    "        sample = {'x':h_f, 'y':lables}\n",
    "        sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:06:57.989264Z",
     "start_time": "2020-01-15T09:06:57.946634Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device):\n",
    "    #save model or not\n",
    "    if args.save_model:\n",
    "        if not os.path.exists(args.save_directory):\n",
    "            os.makedirs(args.save_directory)\n",
    "    \n",
    "    epochs = args.epochs\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch_id in range(epochs):\n",
    "        #monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        ######################\n",
    "        #training the model#\n",
    "        ######################\n",
    "        train_batch_cnt = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            train_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "            \n",
    "            # groundtruth\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #get out_puts\n",
    "            pred_y = model(x)\n",
    "            \n",
    "            #get loss\n",
    "            loss = criterion(y, pred_y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            #do bp\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #show log info\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]  MSELoss: {:.6f}'.format(\n",
    "                        epoch_id,\n",
    "                        batch_idx * len(x),\n",
    "                        len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()\n",
    "                        )\n",
    "                      )\n",
    "        #记录train_loss\n",
    "        train_loss /= train_batch_cnt\n",
    "        train_losses.append(train_loss)\n",
    "            \n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        valid_loss = 0.0\n",
    "        #change model mode to eval ,not use BN/Dropout\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_batch_cnt = 0\n",
    "\n",
    "            for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "                valid_batch_cnt += 1\n",
    "                x = batch['x']\n",
    "                y = batch['y']\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                pred_y = model(x)\n",
    "                \n",
    "                valid_loss_batch = criterion(y, pred_y)\n",
    "                valid_loss += valid_loss_batch.item()\n",
    "\n",
    "            valid_loss /= valid_batch_cnt * 1.0\n",
    "            #记录valid_loss\n",
    "            valid_losses.append(valid_loss)\n",
    "            print('Valid: MSELoss: {:.6f}'.format(valid_loss))\n",
    "        #学习率衰减\n",
    "        scheduler.step()\n",
    "        print('===========================================================')\n",
    "        #save model\n",
    "        if args.save_model and epoch_id % 10 == 0:\n",
    "            saved_model_name = os.path.join(args.save_directory, 'epoch' + '_' + str(epoch_id) + '.pt')\n",
    "            torch.save(model.state_dict(), saved_model_name)\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:06:58.328554Z",
     "start_time": "2020-01-15T09:06:58.284957Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(args, valid_loader, model, criterion, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_batch_cnt = 0\n",
    "        valid_loss = 0\n",
    "        mb_y = 0\n",
    "        mb_pred_y = 0\n",
    "        for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "            valid_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "        \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_y = model(x)\n",
    "            \n",
    "            mb_y += y.mean()\n",
    "            mb_pred_y += pred_y.mean()\n",
    "            \n",
    "            valid_loss_batch = criterion(y, pred_y)\n",
    "            valid_loss += valid_loss_batch.item()\n",
    "\n",
    "        valid_loss /= valid_batch_cnt * 1.0\n",
    "        print('Valid: MSELoss: {:.6f}'.format(valid_loss))\n",
    "        print('MB_Y: {:.2f}, MB_PredY: {:.2f}'.format(mb_y.cpu().numpy(), mb_pred_y.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:06:58.608139Z",
     "start_time": "2020-01-15T09:06:58.571036Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(args, val_set, model, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    data = val_set[args.idx]\n",
    "    with torch.no_grad():\n",
    "        x = data['x'].to(device).unsqueeze(0)\n",
    "        y = data['y'].numpy()\n",
    "        pred_y = model(x)\n",
    "        pred_y = pred_y.cpu().numpy()\n",
    "        plt.figure(0,(8,6))\n",
    "        plt.plot(range(len(y)),y,'b-o')\n",
    "        plt.plot(range(len(y)),pred_y[0],'r-o')\n",
    "        plt.xlabel('Following 72 Hours')\n",
    "        plt.ylabel('AQI')\n",
    "        plt.legend(['obs','predict'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:06:58.731501Z",
     "start_time": "2020-01-15T09:06:58.677118Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #设置随机种子\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #设置CPU/GPU\n",
    "    use_cuda = args.cuda and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    ###############################################################################################################\n",
    "    print('===> Loading Datasets')\n",
    "    #读数据\n",
    "    df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "    data = df.values\n",
    "    data[:,4] /= 10000\n",
    "    #划分样本集\n",
    "    trsf = transforms.Compose([ToTensor()])\n",
    "    train_set = AqiDataset(data[:18000], trsf)\n",
    "    test_set = AqiDataset(data[18000:27000], trsf)\n",
    "    val_set = AqiDataset(data[27000:], trsf)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=False, num_workers= 1, pin_memory= True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size, num_workers= 1, pin_memory= True)\n",
    "    predict_loader = torch.utils.data.DataLoader(val_set, batch_size=args.predict_batch_size, num_workers= 1, pin_memory= False)\n",
    "    ###############################################################################################################\n",
    "    print('===> Building Model')\n",
    "    print('===> runing on {}'.format(device))\n",
    "    ###############################################################################################################\n",
    "    print('===> init model')\n",
    "    model = NetWork()\n",
    "    ###############################################################################################################\n",
    "    model.to(device)\n",
    "#     criterion = nn.MSELoss()\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr= args.lr)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum= args.momentum)\n",
    "    #学习率衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1 , 0.85)\n",
    "    ###############################################################################################################\n",
    "    if args.phase == 'Train' or args.phase == 'train':\n",
    "        print('===> Start Training')\n",
    "        train_losses, valid_losses = train(args, train_loader, test_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Test' or args.phase == 'test':\n",
    "        print('===> Test')\n",
    "        test(args, test_loader, model, criterion, device)\n",
    "        print('===> Done!')\n",
    "        return None, None\n",
    "    elif args.phase == 'Finetune' or args.phase == 'finetune':\n",
    "        print('===> Finetune')\n",
    "        path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        train_losses, valid_losses = train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Predict' or args.phase == 'predict':\n",
    "        print('===> Predict')\n",
    "        predict(args, val_set, model, device)\n",
    "        print('===> Done!')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:04:51.139349Z",
     "start_time": "2020-01-15T10:04:17.232313Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Detector')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=256, metavar='N',\n",
    "                        help='input batch size for testing (default: 256)')\n",
    "    parser.add_argument('--predict_batch_size', type=int, default=1, metavar='N',\n",
    "                        help='input batch size for predict (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=50, metavar='N',\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=10, metavar='S',\n",
    "                        help='random seed (default: 10)')\n",
    "    parser.add_argument('--log_interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save_model', action='store_true', default=False,\n",
    "                        help='save the current Model')\n",
    "    parser.add_argument('--save_directory', type=str, default='trained_models',\n",
    "                        help='learnt models are saving here')\n",
    "    parser.add_argument('--phase', type=str, default='Train',   # Train/train, Predict/predict, Finetune/finetune\n",
    "                        help='training, predicting or finetuning')\n",
    "    parser.add_argument('--number', type=int, default=0,\n",
    "                        help='which model to use')\n",
    "    parser.add_argument('--idx', type=int, default=0,\n",
    "                        help='which sample to predict')\n",
    "    args = parser.parse_args(['--batch_size=64',\n",
    "                              '--test_batch_size=2048',\n",
    "                              '--predict_batch_size=1',\n",
    "                              '--epochs=101',\n",
    "                              '--lr=0.01',\n",
    "                              '--momentum=0.5',\n",
    "                              '--cuda',\n",
    "                              '--seed=1',\n",
    "                              '--log_interval=50',\n",
    "                              '--save_model',\n",
    "                              '--save_directory=trained_models_2',\n",
    "                              '--number=100',\n",
    "                              '--idx=1850',\n",
    "                              '--phase=train'])\n",
    "    ##############################################################################################################\n",
    "    start = time.time()\n",
    "    train_losses, valid_losses = main(args)\n",
    "    end = time.time()\n",
    "    print('耗时：{}s'.format(end - start))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:44:20.713991Z",
     "start_time": "2020-01-15T08:44:19.954805Z"
    }
   },
   "outputs": [],
   "source": [
    "#读数据\n",
    "df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "data = df.values\n",
    "data[:,4] /= 10000\n",
    "#划分样本集\n",
    "trsf = transforms.Compose([ToTensor()])\n",
    "train_set = AqiDataset(data[:18000], trsf)\n",
    "test_set = AqiDataset(data[18000:27000], trsf)\n",
    "val_set = AqiDataset(data[27000:], trsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.3.1",
   "language": "python",
   "name": "torch-1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
