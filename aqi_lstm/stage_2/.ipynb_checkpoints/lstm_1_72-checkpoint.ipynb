{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:26:51.895672Z",
     "start_time": "2020-01-16T06:26:51.119072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "from torch.utils.data import  DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:26:52.658260Z",
     "start_time": "2020-01-16T06:26:52.654868Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_parameters_init(model):\n",
    "    '''\n",
    "    kaiming init\n",
    "    '''\n",
    "    for p in model.parameters():\n",
    "        if len(p.shape) >= 2:\n",
    "            nn.init.kaiming_normal_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:28:46.807814Z",
     "start_time": "2020-01-16T06:28:46.801595Z"
    }
   },
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    '''\n",
    "    只输入一个aqi，其他置0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(NetWork,self).__init__()\n",
    "        self.lstm = nn.LSTM(42, 50, 1, batch_first= True)\n",
    "        self.linear_1 = nn.Linear(50, 50)\n",
    "        self.linear_2 = nn.Linear(50, 1)\n",
    "        self.relu = nn.PReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "#         self.bn = nn.BatchNorm1d(50)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x,(h_1,c_1) = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:28:47.034233Z",
     "start_time": "2020-01-16T06:28:47.031176Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''\n",
    "    transform sample to tensor\n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        sample['x'] = torch.from_numpy(sample['x']).float()\n",
    "        sample['y'] = torch.from_numpy(sample['y']).float()\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:28:47.229326Z",
     "start_time": "2020-01-16T06:28:47.223155Z"
    }
   },
   "outputs": [],
   "source": [
    "class AqiDataset():\n",
    "    '''\n",
    "    用于获取aqi训练与测试数据\n",
    "    '''\n",
    "    def __init__(self, data, transforms= None):\n",
    "        '''\n",
    "        data: samples of ndarray from csv\n",
    "        '''\n",
    "        self.data = data.copy()\n",
    "        #第一个气象要素用不到，只取aqi\n",
    "        #后面71个取不到\n",
    "        self.size = len(data) - 72\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self):\n",
    "        print('使用__getitem__(idx)获取数据')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        定义了__getitem__魔法函数，该类就可以下标操作了：[]\n",
    "        '''\n",
    "        #取此时刻的aqi\n",
    "        aqi = self.data[idx,0]\n",
    "        #将aqi放到下一个时刻的特征上\n",
    "        mete_factors = self.data[idx + 1 : idx + 73].copy()\n",
    "        mete_factors[:,0] = 0\n",
    "        mete_factors[0,0] = aqi\n",
    "        #取各个时刻的实测值\n",
    "        lables = self.data[idx + 1 : idx + 73, 0].copy()\n",
    "        #进行必要的变换\n",
    "        sample = {'x':mete_factors, 'y':lables}\n",
    "        sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:28:47.432612Z",
     "start_time": "2020-01-16T06:28:47.421690Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device):\n",
    "    #save model or not\n",
    "    if args.save_model:\n",
    "        if not os.path.exists(args.save_directory):\n",
    "            os.makedirs(args.save_directory)\n",
    "    \n",
    "    epochs = args.epochs\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch_id in range(epochs):\n",
    "        #monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        ######################\n",
    "        #training the model#\n",
    "        ######################\n",
    "        train_batch_cnt = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            train_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "            \n",
    "            # groundtruth\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #get out_puts\n",
    "            pred_y = model(x)\n",
    "            \n",
    "            #get loss\n",
    "            loss = criterion(y, pred_y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            #do bp\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #show log info\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]  MSELoss: {:.6f}'.format(\n",
    "                        epoch_id,\n",
    "                        batch_idx * len(x),\n",
    "                        len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()\n",
    "                        )\n",
    "                      )\n",
    "        #记录train_loss\n",
    "        train_loss /= train_batch_cnt\n",
    "        train_losses.append(train_loss)\n",
    "            \n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        valid_loss = 0.0\n",
    "        #change model mode to eval ,not use BN/Dropout\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_batch_cnt = 0\n",
    "\n",
    "            for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "                valid_batch_cnt += 1\n",
    "                x = batch['x']\n",
    "                y = batch['y']\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                pred_y = model(x)\n",
    "                \n",
    "                valid_loss_batch = criterion(y, pred_y)\n",
    "                valid_loss += valid_loss_batch.item()\n",
    "\n",
    "            valid_loss /= valid_batch_cnt * 1.0\n",
    "            #记录valid_loss\n",
    "            valid_losses.append(valid_loss)\n",
    "            print('Valid: MSELoss: {:.6f}'.format(valid_loss))\n",
    "        #学习率衰减\n",
    "        scheduler.step()\n",
    "        print('===========================================================')\n",
    "        #save model\n",
    "        if args.save_model and epoch_id % 10 == 0:\n",
    "            saved_model_name = os.path.join(args.save_directory, 'epoch' + '_' + str(epoch_id) + '.pt')\n",
    "            torch.save(model.state_dict(), saved_model_name)\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-16T06:28:50.602Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(args, valid_loader, model, criterion, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_batch_cnt = 0\n",
    "        valid_loss = 0\n",
    "        for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "            valid_batch_cnt += 1\n",
    "            x = batch['x']\n",
    "            y = batch['y']\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred_y = model(x)\n",
    "\n",
    "            valid_loss_batch = criterion(y, pred_y)\n",
    "            valid_loss += valid_loss_batch.item()\n",
    "\n",
    "        valid_loss /= valid_batch_cnt * 1.0\n",
    "        print('Valid: MSELoss: {:.6f}'.format(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:27:52.721768Z",
     "start_time": "2020-01-16T06:27:52.715910Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(args, predict_loader, model, device):\n",
    "    path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "    model.load_state_dict(torch.load(path_model))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    data = val_set[args.idx]\n",
    "    with torch.no_grad():\n",
    "        x = data['x'].to(device).unsqueeze(0)\n",
    "        y = data['y'].numpy()\n",
    "        pred_y = model(x)\n",
    "        pred_y = pred_y.cpu().numpy()\n",
    "        plt.figure(0,(8,6))\n",
    "        plt.plot(range(len(y)),y,'b-o')\n",
    "        plt.plot(range(len(y)),pred_y[0],'r-o')\n",
    "        plt.xlabel('Following 72 Hours')\n",
    "        plt.ylabel('AQI')\n",
    "        plt.legend(['obs','predict'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:27:55.511199Z",
     "start_time": "2020-01-16T06:27:55.498766Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #设置随机种子\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #设置CPU/GPU\n",
    "    use_cuda = args.cuda and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    ###############################################################################################################\n",
    "    print('===> Loading Datasets')\n",
    "    #读数据\n",
    "    df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "    data = df.values\n",
    "    data[:,4] /= 10000\n",
    "    #划分样本集\n",
    "    trsf = transforms.Compose([ToTensor()])\n",
    "    train_set = AqiDataset(data[:18000], trsf)\n",
    "    test_set = AqiDataset(data[18000:27000], trsf)\n",
    "    val_set = AqiDataset(data[27000:], trsf)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=False, num_workers= 1, pin_memory= False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size, num_workers= 1, pin_memory= False)\n",
    "    predict_loader = torch.utils.data.DataLoader(val_set, batch_size=args.predict_batch_size, num_workers= 1, pin_memory= False)\n",
    "    ###############################################################################################################\n",
    "    print('===> Building Model')\n",
    "    print('===> runing on {}'.format(device))\n",
    "    ###############################################################################################################\n",
    "    print('===> init model')\n",
    "    model = NetWork()\n",
    "    ###############################################################################################################\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr= args.lr)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum= args.momentum)\n",
    "    #学习率衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 1 , 0.9)\n",
    "    ###############################################################################################################\n",
    "    if args.phase == 'Train' or args.phase == 'train':\n",
    "        print('===> Start Training')\n",
    "        train_losses, valid_losses = train(args, train_loader, test_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Test' or args.phase == 'test':\n",
    "        print('===> Test')\n",
    "        test(args, test_loader, model, criterion, device)\n",
    "        print('===> Done!')\n",
    "        return None, None\n",
    "    elif args.phase == 'Finetune' or args.phase == 'finetune':\n",
    "        print('===> Finetune')\n",
    "        path_model = os.path.join(args.save_directory, 'epoch' + '_' + str(args.number) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        train_losses, valid_losses = train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Predict' or args.phase == 'predict':\n",
    "        print('===> Predict')\n",
    "        predict(args, predict_loader, model, device)\n",
    "        print('===> Done!')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T06:28:24.503801Z",
     "start_time": "2020-01-16T06:28:20.783451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading Datasets\n",
      "===> Building Model\n",
      "===> runing on cuda\n",
      "===> init model\n",
      "===> Start Training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 41, got 42",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-963521e04bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m##############################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'耗时：{}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-019fd8708019>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Train'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===> Start Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===> Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a1ef7c68bbd6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#get out_puts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c8197fb89f8e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt1/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 149\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 41, got 42"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Detector')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=256, metavar='N',\n",
    "                        help='input batch size for testing (default: 256)')\n",
    "    parser.add_argument('--predict_batch_size', type=int, default=1, metavar='N',\n",
    "                        help='input batch size for predict (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=50, metavar='N',\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=10, metavar='S',\n",
    "                        help='random seed (default: 10)')\n",
    "    parser.add_argument('--log_interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save_model', action='store_true', default=False,\n",
    "                        help='save the current Model')\n",
    "    parser.add_argument('--save_directory', type=str, default='trained_models',\n",
    "                        help='learnt models are saving here')\n",
    "    parser.add_argument('--phase', type=str, default='Train',   # Train/train, Predict/predict, Finetune/finetune\n",
    "                        help='training, predicting or finetuning')\n",
    "    parser.add_argument('--number', type=int, default=0,\n",
    "                        help='which model to use')\n",
    "    parser.add_argument('--idx', type=int, default=0,\n",
    "                        help='which sample to predict')\n",
    "    args = parser.parse_args(['--batch_size=64',\n",
    "                              '--test_batch_size=2048',\n",
    "                              '--predict_batch_size=1',\n",
    "                              '--epochs=21',\n",
    "                              '--lr=0.00001',\n",
    "                              '--momentum=0.2',\n",
    "                              '--cuda',\n",
    "                              '--seed=1',\n",
    "                              '--log_interval=50',\n",
    "                              '--save_model',\n",
    "                              '--save_directory=trained_models',\n",
    "                              '--number=9999',\n",
    "                              '--idx=1550',\n",
    "                              '--phase=train'])\n",
    "    ##############################################################################################################\n",
    "    start = time.time()\n",
    "    train_losses, valid_losses = main(args)\n",
    "    end = time.time()\n",
    "    print('耗时：{}s'.format(end - start))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:56:53.960083Z",
     "start_time": "2020-01-10T09:56:53.872678Z"
    }
   },
   "outputs": [],
   "source": [
    "#读数据\n",
    "df = pd.read_csv('data/aqi_upsample.csv',index_col= 0)\n",
    "data = df.values\n",
    "data[:,4] /= 10000\n",
    "#划分样本集\n",
    "trsf = transforms.Compose([ToTensor()])\n",
    "train_set = AqiDataset(data[:18000], trsf)\n",
    "test_set = AqiDataset(data[18000:27000], trsf)\n",
    "val_set = AqiDataset(data[27000:], trsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T10:07:55.740721Z",
     "start_time": "2020-01-10T10:07:55.734231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[ 1.7000e+01,  1.1740e+01, -6.2700e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -7.1000e-01],\n",
       "         [ 0.0000e+00,  1.1990e+01, -6.5600e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -5.7000e-01],\n",
       "         [ 0.0000e+00,  1.2240e+01, -6.8600e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -4.2000e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  2.0990e+01, -1.2860e+01,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -5.0000e-02],\n",
       "         [ 0.0000e+00,  2.0450e+01, -1.2790e+01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  1.0000e-02],\n",
       "         [ 0.0000e+00,  1.9900e+01, -1.2720e+01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  8.0000e-02]]),\n",
       " 'y': tensor([16.0000, 16.1100, 16.2200, 16.3300, 16.4400, 16.5600, 16.6700, 16.7800,\n",
       "         16.8900, 17.0000, 18.3300, 19.6700, 21.0000, 21.3300, 21.6700, 22.0000,\n",
       "         22.3300, 22.6700, 23.0000, 24.0800, 25.1500, 26.2300, 27.3100, 28.3800,\n",
       "         29.4600, 30.5400, 31.6200, 32.6900, 33.7700, 34.8500, 35.9200, 37.0000,\n",
       "         38.0800, 39.1500, 40.2300, 41.3100, 42.3800, 43.4600, 44.5400, 45.6200,\n",
       "         46.6900, 47.7700, 48.8500, 49.9200, 51.0000, 52.0800, 53.1500, 54.2300,\n",
       "         55.3100, 56.3800, 57.4600, 58.5400, 59.6200, 60.6900, 61.7700, 62.8500,\n",
       "         63.9200, 65.0000, 72.0000, 79.0000, 86.0000, 77.6700, 69.3300, 61.0000,\n",
       "         58.6700, 56.3300, 54.0000, 51.4700, 48.9300, 46.4000, 43.8700, 41.3300])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set[2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.3.1",
   "language": "python",
   "name": "torch-1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
